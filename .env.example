# ======================================
# GitHub Agent Demo - 环境变量配置
# ======================================

# --- LLM 供应商选择 ---
# 支持: openai, deepseek, anthropic, gemini
# 默认: deepseek
LLM_PROVIDER=deepseek

# --- API Keys (根据选择的供应商配置对应的 Key) ---

# OpenAI (如果 LLM_PROVIDER=openai)
OPENAI_API_KEY=
# OPENAI_BASE_URL=  # 可选: 自定义端点 (如 Azure OpenAI)

# DeepSeek (如果 LLM_PROVIDER=deepseek)
DEEPSEEK_API_KEY=
# DEEPSEEK_BASE_URL=https://api.deepseek.com  # 可选: 默认值

# Anthropic Claude (如果 LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=

# Google Gemini (如果 LLM_PROVIDER=gemini)
GEMINI_API_KEY=
# GEMINI_BASE_URL=  # 可选: OpenAI 兼容端点

# --- 模型配置 ---
# 如果不指定，将使用各供应商的默认模型:
# - openai: gpt-4o-mini
# - deepseek: deepseek-chat
# - anthropic: claude-3-5-sonnet-20241022
# - gemini: gemini-1.5-flash
# MODEL_NAME=deepseek-chat

# --- GitHub Token ---
# 用于访问 GitHub API，提高请求限制
GITHUB_TOKEN=

# --- Embedding 服务 ---
# SiliconFlow API Key (用于 BGE-M3 Embedding)
SILICON_API_KEY=

# --- Qdrant 向量数据库配置 ---
# 本地模式 (默认): 数据存储在 data/qdrant_db
QDRANT_USE_LOCAL=true
QDRANT_PATH=data/qdrant_db

# 远程模式: 连接 Qdrant Cloud 或自托管服务
# QDRANT_USE_LOCAL=false
# QDRANT_HOST=localhost
# QDRANT_PORT=6333
# QDRANT_API_KEY=

# 向量维度 (BGE-M3 = 1024)
# QDRANT_VECTOR_SIZE=1024

# --- 服务配置 ---
# HOST=127.0.0.1
# PORT=8000

# --- LLM 参数 (可选) ---
# LLM_TEMPERATURE=0.1
# LLM_MAX_TOKENS=4096
# LLM_TIMEOUT=600