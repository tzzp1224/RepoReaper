# æ–‡ä»¶è·¯å¾„: evaluation/golden_dataset_builder.py
"""
é»„é‡‘æ•°æ®é›†æ„å»ºå·¥å…·
ç”¨äºå¿«é€Ÿæ„å»ºè¯„ä¼°æ‰€éœ€çš„æ ‡æ³¨æ•°æ®é›†

ä½¿ç”¨åœºæ™¯:
1. åˆå§‹åŒ–: ä¸ºæ–°é¡¹ç›®å¿«é€Ÿåˆ›å»º 50 æ¡æµ‹è¯•ç”¨ä¾‹
2. æ‰©å±•: å®šæœŸæ·»åŠ æ–°çš„é—®é¢˜å’Œæ ‡æ³¨
3. éªŒè¯: è‡ªåŠ¨éªŒè¯æ•°æ®é›†çš„å®Œæ•´æ€§

Author: Dexter
Date: 2025-01-27
"""

import json
import os
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class GoldenSample:
    """é»„é‡‘æ•°æ®é›†æ ·æœ¬"""
    id: str                           # å”¯ä¸€ID
    description: str                  # é—®é¢˜æè¿° (ç”¨äºæ ‡æ³¨äººå‘˜ç†è§£é—®é¢˜ç±»å‹)
    query: str                        # ç”¨æˆ·æŸ¥è¯¢
    expected_files: List[str]         # æ ‡å‡†ç­”æ¡ˆ: åº”è¯¥è¿”å›çš„æ–‡ä»¶åˆ—è¡¨
    expected_answer: str = ""         # æ ‡å‡†ç­”æ¡ˆ: é¢„æœŸå›ç­” (å¯é€‰)
    difficulty: str = "medium"        # éš¾åº¦: easy/medium/hard
    category: str = "general"         # ç±»åˆ«: general/code_finding/architecture/workflow
    language: str = "en"              # è¯­è¨€: en/zh
    created_at: str = ""
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()


class GoldenDatasetBuilder:
    """é»„é‡‘æ•°æ®é›†æ„å»ºå™¨"""
    
    def __init__(self, filepath: str = "evaluation/golden_dataset.json"):
        self.filepath = filepath
        self.samples: List[GoldenSample] = []
        self.load()
    
    def load(self):
        """åŠ è½½ç°æœ‰æ•°æ®é›†"""
        if os.path.exists(self.filepath):
            with open(self.filepath, 'r', encoding='utf-8') as f:
                try:
                    raw_data = json.load(f)
                    # å…¼å®¹æ—§æ ¼å¼ (ç›´æ¥æ˜¯å­—å…¸åˆ—è¡¨)
                    if isinstance(raw_data, list):
                        self.samples = [
                            GoldenSample(**item) if isinstance(item, dict) and "id" in item
                            else GoldenSample(
                                id=str(len(self.samples)),
                                description=item.get("description", ""),
                                query=item.get("query", ""),
                                expected_files=[item.get("answer_file", "")] if item.get("answer_file") else []
                            )
                            for item in raw_data
                        ]
                except:
                    self.samples = []
    
    def save(self):
        """ä¿å­˜æ•°æ®é›†"""
        os.makedirs(os.path.dirname(self.filepath), exist_ok=True)
        data = [asdict(s) for s in self.samples]
        with open(self.filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def add_sample(self, sample: GoldenSample):
        """æ·»åŠ æ ·æœ¬"""
        sample.id = f"sample_{len(self.samples):04d}"
        self.samples.append(sample)
    
    def add_samples_batch(self, samples: List[GoldenSample]):
        """æ‰¹é‡æ·»åŠ æ ·æœ¬"""
        for sample in samples:
            self.add_sample(sample)
    
    def get_samples_by_category(self, category: str) -> List[GoldenSample]:
        """æŒ‰ç±»åˆ«ç­›é€‰"""
        return [s for s in self.samples if s.category == category]
    
    def get_samples_by_difficulty(self, difficulty: str) -> List[GoldenSample]:
        """æŒ‰éš¾åº¦ç­›é€‰"""
        return [s for s in self.samples if s.difficulty == difficulty]
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total": len(self.samples),
            "by_category": {},
            "by_difficulty": {},
            "by_language": {}
        }
        
        for s in self.samples:
            stats["by_category"][s.category] = stats["by_category"].get(s.category, 0) + 1
            stats["by_difficulty"][s.difficulty] = stats["by_difficulty"].get(s.difficulty, 0) + 1
            stats["by_language"][s.language] = stats["by_language"].get(s.language, 0) + 1
        
        return stats


# ============================================================================
# é¢„å®šä¹‰çš„é€šç”¨é—®é¢˜æ¨¡æ¿
# ============================================================================

# é’ˆå¯¹ FastAPI é¡¹ç›®çš„åˆå§‹æ•°æ®é›† (å‚è€ƒä½ ç°æœ‰çš„ golden_dataset.json)
FASTAPI_GOLDEN_SAMPLES = [
    # Easy: ä»£ç ä½ç½®æŸ¥æ‰¾
    GoldenSample(
        id="",
        description="ç®€å•å‡½æ•°æŸ¥æ‰¾",
        query="Where is the 'serialize_response' function?",
        expected_files=["fastapi/routing.py"],
        difficulty="easy",
        category="code_finding"
    ),
    
    # Medium: ç†è§£æ•°æ®æµ
    GoldenSample(
        id="",
        description="ç†è§£æ ¸å¿ƒæ¨¡å—èŒè´£",
        query="How does dependency injection work in FastAPI?",
        expected_files=["fastapi/dependencies/utils.py", "fastapi/depends.py"],
        difficulty="medium",
        category="architecture"
    ),
    
    # Hard: è·¨æ–‡ä»¶ç†è§£å·¥ä½œæµ
    GoldenSample(
        id="",
        description="å®Œæ•´å·¥ä½œæµç†è§£",
        query="Show me the complete flow from request to response in FastAPI",
        expected_files=["fastapi/routing.py", "fastapi/applications.py", "fastapi/dependencies/utils.py"],
        difficulty="hard",
        category="workflow"
    ),
]

# GitHub Agent é¡¹ç›®çš„åˆå§‹æ•°æ®é›†
GITHUB_AGENT_GOLDEN_SAMPLES = [
    GoldenSample(
        id="",
        description="æ£€ç´¢æ ¸å¿ƒé€»è¾‘",
        query="How is chunk_file method implemented?",
        expected_files=["app/services/chunking_service.py"],
        expected_answer="The chunk_file method is implemented in chunking_service.py. It takes content and file_path as parameters and uses AST parsing for Python files to intelligently chunk the code.",
        difficulty="easy",
        category="code_finding",
        language="en"
    ),
    
    GoldenSample(
        id="",
        description="å‘é‡æœç´¢æœºåˆ¶",
        query="What vector database is used for retrieval?",
        expected_files=["app/services/vector_service.py"],
        difficulty="medium",
        category="architecture",
        language="en"
    ),
    
    GoldenSample(
        id="",
        description="å®Œæ•´åˆ†ææµç¨‹",
        query="How does the agent analyze a GitHub repository?",
        expected_files=["app/services/agent_service.py", "app/services/chunking_service.py", "app/services/vector_service.py"],
        difficulty="hard",
        category="workflow",
        language="en"
    ),
]


# ============================================================================
# äº¤äº’å¼æ•°æ®é›†æ„å»ºå·¥å…·
# ============================================================================

def interactive_builder():
    """äº¤äº’å¼æ„å»ºé»„é‡‘æ•°æ®é›†"""
    builder = GoldenDatasetBuilder()
    
    print("=" * 60)
    print("ğŸ› ï¸  é»„é‡‘æ•°æ®é›†æ„å»ºå·¥å…·")
    print("=" * 60)
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. æ·»åŠ æ–°æ ·æœ¬")
        print("2. æŸ¥çœ‹ç°æœ‰æ ·æœ¬")
        print("3. æŒ‰ç±»åˆ«ç­›é€‰")
        print("4. ç»Ÿè®¡ä¿¡æ¯")
        print("5. ä¿å­˜å¹¶é€€å‡º")
        print("0. é€€å‡º(ä¸ä¿å­˜)")
        
        choice = input("è¯·è¾“å…¥é€‰é¡¹ (0-5): ").strip()
        
        if choice == "1":
            sample = GoldenSample(
                id="",
                description=input("ğŸ“ æè¿° (é—®é¢˜ç±»å‹): "),
                query=input("â“ æŸ¥è¯¢/é—®é¢˜: "),
                expected_files=input("ğŸ“ é¢„æœŸæ–‡ä»¶ (é€—å·åˆ†éš”): ").split(","),
                expected_answer=input("ğŸ“„ æ ‡å‡†ç­”æ¡ˆ (å¯é€‰): "),
                difficulty=input("â­ éš¾åº¦ (easy/medium/hard) [medium]: ") or "medium",
                category=input("ğŸ·ï¸  ç±»åˆ« (code_finding/architecture/workflow/general) [general]: ") or "general",
                language=input("ğŸŒ è¯­è¨€ (en/zh) [en]: ") or "en"
            )
            builder.add_sample(sample)
            print("âœ… æ ·æœ¬å·²æ·»åŠ ")
        
        elif choice == "2":
            print(f"\næ€»å…± {len(builder.samples)} ä¸ªæ ·æœ¬:")
            for s in builder.samples[-10:]:  # æ˜¾ç¤ºæœ€å10ä¸ª
                print(f"  - [{s.difficulty}] {s.query[:50]}")
        
        elif choice == "3":
            category = input("è¾“å…¥ç±»åˆ«: ")
            samples = builder.get_samples_by_category(category)
            print(f"\næ‰¾åˆ° {len(samples)} ä¸ª '{category}' ç±»åˆ«çš„æ ·æœ¬:")
            for s in samples:
                print(f"  - {s.query}")
        
        elif choice == "4":
            stats = builder.get_statistics()
            print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
            print(f"  æ€»æ ·æœ¬æ•°: {stats['total']}")
            print(f"  æŒ‰ç±»åˆ«: {stats['by_category']}")
            print(f"  æŒ‰éš¾åº¦: {stats['by_difficulty']}")
            print(f"  æŒ‰è¯­è¨€: {stats['by_language']}")
        
        elif choice == "5":
            builder.save()
            print("âœ… æ•°æ®é›†å·²ä¿å­˜")
            break
        
        elif choice == "0":
            print("âš ï¸ æœªä¿å­˜,é€€å‡º")
            break


# ============================================================================
# è‡ªåŠ¨è¯„ä¼°æ•°æ®é›†çš„å®Œæ•´æ€§
# ============================================================================

def validate_golden_dataset(filepath: str = "evaluation/golden_dataset.json") -> Dict:
    """éªŒè¯é»„é‡‘æ•°æ®é›†çš„å®Œæ•´æ€§"""
    
    builder = GoldenDatasetBuilder(filepath)
    issues = {
        "missing_fields": [],
        "empty_queries": [],
        "empty_files": [],
        "duplicates": []
    }
    
    seen_queries = set()
    
    for i, sample in enumerate(builder.samples):
        # æ£€æŸ¥å¿…å¡«å­—æ®µ
        if not sample.query:
            issues["empty_queries"].append(f"Sample {i}: query is empty")
        
        if not sample.expected_files or all(not f for f in sample.expected_files):
            issues["empty_files"].append(f"Sample {i}: expected_files is empty")
        
        # æ£€æŸ¥é‡å¤
        if sample.query in seen_queries:
            issues["duplicates"].append(f"Sample {i}: duplicate query")
        seen_queries.add(sample.query)
    
    return {
        "valid": len(issues) == 0 or not any(issues.values()),
        "total_samples": len(builder.samples),
        "issues": issues,
        "stats": builder.get_statistics()
    }


# ============================================================================
# å¿«é€Ÿåˆå§‹åŒ–è„šæœ¬
# ============================================================================

def init_github_agent_dataset():
    """å¿«é€Ÿåˆå§‹åŒ– GitHub Agent é¡¹ç›®çš„æ•°æ®é›†"""
    builder = GoldenDatasetBuilder("evaluation/golden_dataset.json")
    
    # æ¸…ç©ºç°æœ‰ (å¯é€‰)
    # builder.samples = []
    
    # æ·»åŠ åˆå§‹æ ·æœ¬
    builder.add_samples_batch(GITHUB_AGENT_GOLDEN_SAMPLES)
    
    # é¢å¤–æ·»åŠ æ›´å¤šæ ·æœ¬ (æ‰©å±•åˆ°30+)
    extra_samples = [
        GoldenSample(
            id="",
            description="å‘é‡æ£€ç´¢è´¨é‡",
            query="What retrieval metrics are tracked?",
            expected_files=["evaluation/evaluation_framework.py"],
            difficulty="medium",
            category="architecture"
        ),
        GoldenSample(
            id="",
            description="Agentå†³ç­–è¿‡ç¨‹",
            query="How does the agent decide which files to read?",
            expected_files=["app/services/agent_service.py"],
            difficulty="hard",
            category="workflow"
        ),
        GoldenSample(
            id="",
            description="é”™è¯¯å¤„ç†",
            query="Where are network timeout errors handled?",
            expected_files=["app/services/agent_service.py", "app/services/chat_service.py"],
            difficulty="medium",
            category="code_finding"
        ),
    ]
    builder.add_samples_batch(extra_samples)
    builder.save()
    
    print(f"âœ… åˆå§‹åŒ–å®Œæˆ: {len(builder.samples)} ä¸ªæ ·æœ¬")
    print(f"ğŸ“Š {builder.get_statistics()}")


# ============================================================================
# å¯¼å‡ºä¸º Ragas æ ¼å¼
# ============================================================================

def export_to_ragas_format(golden_filepath: str, output_filepath: str = "evaluation/ragas_eval_dataset.json"):
    """
    å°†é»„é‡‘æ•°æ®é›†å¯¼å‡ºä¸º Ragas è¯„ä¼°æ¡†æ¶æ‰€éœ€çš„æ ¼å¼
    
    Ragas æ ¼å¼:
    {
        "questions": [...],
        "contexts": [...],
        "ground_truths": [...]
    }
    """
    builder = GoldenDatasetBuilder(golden_filepath)
    
    ragas_data = {
        "questions": [],
        "contexts": [],
        "ground_truths": [],
        "metadata": []
    }
    
    for sample in builder.samples:
        ragas_data["questions"].append(sample.query)
        ragas_data["ground_truths"].append({
            "answer": sample.expected_answer,
            "files": sample.expected_files
        })
        ragas_data["contexts"].append("\n".join(sample.expected_files))
        ragas_data["metadata"].append({
            "difficulty": sample.difficulty,
            "category": sample.category,
            "description": sample.description
        })
    
    os.makedirs(os.path.dirname(output_filepath), exist_ok=True)
    with open(output_filepath, 'w', encoding='utf-8') as f:
        json.dump(ragas_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Exported to {output_filepath}")
    print(f"   Questions: {len(ragas_data['questions'])}")


# ============================================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "init":
            init_github_agent_dataset()
        
        elif command == "validate":
            result = validate_golden_dataset()
            print(json.dumps(result, indent=2, ensure_ascii=False))
        
        elif command == "export-ragas":
            export_to_ragas_format("evaluation/golden_dataset.json")
        
        elif command == "interactive":
            interactive_builder()
        
        else:
            print(f"Unknown command: {command}")
    
    else:
        print("é»„é‡‘æ•°æ®é›†æ„å»ºå·¥å…·")
        print()
        print("ç”¨æ³•:")
        print("  python golden_dataset_builder.py init              # å¿«é€Ÿåˆå§‹åŒ–")
        print("  python golden_dataset_builder.py validate          # éªŒè¯æ•°æ®é›†")
        print("  python golden_dataset_builder.py export-ragas      # å¯¼å‡ºä¸ºRagasæ ¼å¼")
        print("  python golden_dataset_builder.py interactive       # äº¤äº’å¼æ„å»º")
