# æ–‡ä»¶è·¯å¾„: app/services/agent_service.py
import json
import asyncio
from app.core.config import settings
from app.utils.llm_client import client
from app.services.github_service import get_repo_structure, get_file_content
from app.services.vector_service import vector_db  # å¼•ç”¨å•ä¾‹

async def agent_stream(repo_url: str):
    """
    Agent æ ¸å¿ƒå·¥ä½œæµï¼šæ„ŸçŸ¥ -> è§„åˆ’ -> æ‰§è¡Œ -> æŠ¥å‘Š
    """
    # Step 1: åˆå§‹åŒ–
    yield json.dumps({"step": "init", "message": f"ğŸš€ æ­£åœ¨è¿æ¥ GitHub: {repo_url}..."})
    await asyncio.sleep(0.5)
    
    try:
        # é‡ç½®å‘é‡åº“
        vector_db.reset_collection()

        # è·å–ç›®å½•ç»“æ„
        file_list = get_repo_structure(repo_url)
        if not file_list:
            yield json.dumps({"step": "error", "message": "âŒ æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥ URLã€‚"})
            return

        yield json.dumps({"step": "fetched", "message": f"ğŸ“¦ è·å–æˆåŠŸï¼å…±å‘ç° {len(file_list)} ä¸ªæ–‡ä»¶ã€‚"})
        
        # æˆªå–å‰ 400 ä¸ªæ–‡ä»¶ï¼Œé˜²æ­¢ Token è¶…å‡ºé™åˆ¶
        limit = 400
        file_list_str = "\n".join(file_list[:limit])

        # Step 2: è§„åˆ’ (Gemini Thinking)
        yield json.dumps({"step": "thinking", "message": "ğŸ¤– Gemini æ­£åœ¨é˜…è¯»ç›®å½•ï¼ŒæŒ‘é€‰æ ¸å¿ƒä»£ç ..."})
        
        selection_prompt = f"""
        You are a Senior Software Architect.
        Repo Structure:
        {file_list_str}
        
        Identify top 3-5 critical files to understand the project architecture and logic.
        Return ONLY a raw JSON list of strings. 
        Example: ["README.md", "main.py", "app/core/config.py"]
        """
        
        if not client:
             yield json.dumps({"step": "error", "message": "âŒ LLM Client æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ API Keyã€‚"})
             return

        response = client.models.generate_content(
            model=settings.MODEL_NAME, 
            contents=selection_prompt
        )
        
        selected_files = ["README.md"]
        try:
            # æ¸…æ´— JSON
            clean_text = response.text.replace("```json", "").replace("```", "").strip()
            selected_files = json.loads(clean_text)
        except:
            print("âš ï¸ JSON è§£æå¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤æ–‡ä»¶")

        yield json.dumps({"step": "plan", "message": f"ğŸ¯ å†³å®šæ·±å…¥é˜…è¯»: {selected_files}"})
        
        # Step 3: ç´¢å¼• (Indexing)
        code_context = ""
        documents = []
        metadatas = []

        for i, file_path in enumerate(selected_files):
            yield json.dumps({"step": "download", "message": f"ğŸ“¥ [{i+1}/{len(selected_files)}] è¯»å–å¹¶å‘é‡åŒ–: {file_path}..."})
            content = get_file_content(repo_url, file_path)
            if content:
                # ç®€å•åˆ‡åˆ†ï¼šå–å‰ 8000 å­—ç¬¦ä½œä¸º Context
                snippet = content[:8000]
                documents.append(snippet)
                metadatas.append({"file": file_path})
                code_context += f"\n\n=== FILE: {file_path} ===\n{snippet}"
        
        yield json.dumps({"step": "indexing", "message": "ğŸ§  æ­£åœ¨æ„å»º RAG å‘é‡ç´¢å¼•..."})
        vector_db.add_documents(documents, metadatas)

        # Step 4: ç”ŸæˆæŠ¥å‘Š (Reporting)
        yield json.dumps({"step": "generating", "message": "ğŸ“ æ­£åœ¨æ’°å†™æ¶æ„åˆ†ææŠ¥å‘Š..."})
        
        analysis_prompt = f"""
        You are a Tech Lead.
        Based on the code context below:
        {code_context}
        
        Write a concise technical report (in Chinese). Use Markdown.
        Cover: Project Purpose, Tech Stack, and Key Architecture.
        """
        
        # å°è¯•æµå¼ç”Ÿæˆ
        try:
            stream = client.models.generate_content_stream(
                model=settings.MODEL_NAME, 
                contents=analysis_prompt
            )
            for chunk in stream:
                yield json.dumps({"step": "report_chunk", "chunk": chunk.text})
                await asyncio.sleep(0.02)
        except Exception as e:
            # å›é€€åˆ°éæµå¼
            resp = client.models.generate_content(
                model=settings.MODEL_NAME, contents=analysis_prompt
            )
            yield json.dumps({"step": "report_chunk", "chunk": resp.text})

        yield json.dumps({"step": "finish", "message": "âœ… åˆ†æå®Œæˆï¼ç°åœ¨å¯ä»¥æé—®äº†ã€‚"})

    except Exception as e:
        import traceback
        traceback.print_exc()
        yield json.dumps({"step": "error", "message": f"ğŸ’¥ ç³»ç»Ÿé”™è¯¯: {str(e)}"})