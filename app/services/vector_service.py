# æ–‡ä»¶è·¯å¾„: app/services/vector_service.py
import chromadb
from chromadb.config import Settings as ChromaSettings
from app.utils.llm_client import client
from app.core.config import settings

# æ–°å¢ä¾èµ–
from rank_bm25 import BM25Okapi
import jieba # å¦‚æœå¤„ç†ä¸­æ–‡æ³¨é‡Šå¯èƒ½éœ€è¦ï¼Œçº¯ä»£ç åˆ†è¯å¯ä»¥ç”¨ç®€å•çš„ split
import re

class VectorStore:
    def __init__(self):
        # åˆå§‹åŒ– ChromaDB (å†…å­˜æ¨¡å¼)
        self.chroma_client = chromadb.Client(ChromaSettings(anonymized_telemetry=False))
        self.collection_name = "repo_code"
        
        # === Hybrid Search ç»„ä»¶ ===
        self.bm25 = None
        self.doc_store = [] # å­˜å‚¨ {"id":..., "content":..., "file":...} ç”¨äº BM25
        
        self.reset_collection()

    def reset_collection(self):
        """é‡ç½®é›†åˆä¸å†…å­˜ç´¢å¼•"""
        try:
            self.chroma_client.delete_collection(name=self.collection_name)
        except Exception:
            pass
        self.collection = self.chroma_client.create_collection(name=self.collection_name)
        
        # é‡ç½® BM25 ç›¸å…³æ•°æ®
        self.bm25 = None
        self.doc_store = []
        print("ğŸ§¹ [VectorDB] æ•°æ®åº“ä¸ BM25 ç´¢å¼•å·²é‡ç½®")

    def embed_text(self, text):
        """è°ƒç”¨ Gemini ç”Ÿæˆ Embedding"""
        if not client:
            return []
        try:
            result = client.models.embed_content(
                model=settings.EMBEDDING_MODEL,
                contents=text
            )
            return result.embeddings[0].values
        except Exception as e:
            print(f"âŒ Embedding ç”Ÿæˆå¤±è´¥: {e}")
            return []

    def _tokenize(self, text):
        """ç®€å•çš„ä»£ç åˆ†è¯ï¼šæŒ‰éå­—æ¯æ•°å­—å­—ç¬¦åˆ‡åˆ†"""
        # å°†ä»£ç è½¬ä¸º token åˆ—è¡¨ï¼Œä¾‹å¦‚ "def my_func" -> ["def", "my", "func"]
        return [t.lower() for t in re.split(r'[^a-zA-Z0-9]', text) if t.strip()]

    def add_documents(self, documents, metadatas):
        """
        æ‰¹é‡æ·»åŠ æ–‡æ¡£ï¼š
        1. å­˜å…¥ Chroma (å‘é‡æ£€ç´¢)
        2. å­˜å…¥å†…å­˜åˆ—è¡¨å¹¶æ„å»º BM25 (å…³é”®è¯æ£€ç´¢)
        """
        if not documents: return

        embeddings = []
        ids = []
        
        print(f"ğŸ§  [VectorDB] æ­£åœ¨å¤„ç† {len(documents)} ä¸ªç‰‡æ®µ (Vector + BM25)...")
        
        # 1. å‡†å¤‡å‘é‡æ•°æ®
        for i, doc in enumerate(documents):
            # ç”Ÿæˆå”¯ä¸€ ID
            doc_id = f"{metadatas[i]['file']}_{len(self.doc_store) + i}"
            
            # å­˜å…¥ BM25 å­˜å‚¨åŒº
            self.doc_store.append({
                "id": doc_id,
                "content": doc,
                "metadata": metadatas[i]
            })
            
            # ç”Ÿæˆå‘é‡
            emb = self.embed_text(doc)
            if emb:
                embeddings.append(emb)
                ids.append(doc_id)

        # 2. å†™å…¥ Chroma
        if embeddings:
            self.collection.add(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
        
        # 3. é‡å»º BM25 ç´¢å¼• (æ³¨æ„ï¼šæ¯æ¬¡æ·»åŠ éƒ½ä¼šå…¨é‡é‡å»ºï¼Œç”Ÿäº§ç¯å¢ƒéœ€ä¼˜åŒ–ï¼Œä½†åœ¨ Demo ä¸­å¯æ¥å—)
        tokenized_corpus = [self._tokenize(doc['content']) for doc in self.doc_store]
        self.bm25 = BM25Okapi(tokenized_corpus)
        
        print(f"âœ… [VectorDB] å·²ç´¢å¼• {len(documents)} ä¸ªç‰‡æ®µ")

    def search_hybrid(self, query, top_k=3):
        """
        æ··åˆæ£€ç´¢ï¼šVector + BM25 + RRF Fusion
        """
        # 1. å‘é‡æ£€ç´¢ç»“æœ
        vector_results = []
        query_embedding = self.embed_text(query)
        if query_embedding:
            chroma_res = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k * 2 # å–å¤šä¸€ç‚¹ç”¨äºèåˆ
            )
            if chroma_res['ids']:
                # æ•´ç†æ ¼å¼
                ids = chroma_res['ids'][0]
                docs = chroma_res['documents'][0]
                metas = chroma_res['metadatas'][0]
                for i in range(len(ids)):
                    vector_results.append({
                        "id": ids[i],
                        "content": docs[i],
                        "file": metas[i]['file'],
                        "score": 0 # RRF ä¸­åˆ†æ•°ç”±æ’åå†³å®š
                    })

        # 2. BM25 æ£€ç´¢ç»“æœ
        bm25_results = []
        if self.bm25:
            tokenized_query = self._tokenize(query)
            # è·å–æ‰€æœ‰æ–‡æ¡£çš„åˆ†æ•°
            doc_scores = self.bm25.get_scores(tokenized_query)
            # è·å– top_k * 2 çš„ç´¢å¼•
            top_n = min(len(doc_scores), top_k * 2)
            top_indices = sorted(range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:top_n]
            
            for idx in top_indices:
                if doc_scores[idx] > 0: # åªä¿ç•™æœ‰åŒ¹é…çš„
                    doc_item = self.doc_store[idx]
                    bm25_results.append({
                        "id": doc_item["id"],
                        "content": doc_item["content"],
                        "file": doc_item["metadata"]["file"],
                        "score": 0
                    })

        # 3. RRF (Reciprocal Rank Fusion) èåˆ
        # ç®—æ³•ï¼šScore = 1 / (k + rank)
        k = 60
        fused_scores = {}
        
        # === æ ¸å¿ƒè°ƒæ•´ï¼šè®¾ç½®æƒé‡ ===
        # å‘é‡æœç´¢é€šå¸¸æ›´å‡†ï¼Œç»™é«˜æƒé‡ (1.0)
        # BM25 ä¸»è¦ç”¨äºæ•æ‰ä¸“æœ‰åè¯ï¼Œä½†åœ¨é€šç”¨å¥å­é‡Œå™ªéŸ³å¤§ï¼Œç»™ä½æƒé‡ (0.3 - 0.5)
        weight_vector = 1.0
        weight_bm25 = 0.3  # <--- é™ä½ BM25 çš„è¯è¯­æƒ

        # å¤„ç†å‘é‡ç»“æœ (åŠ æƒ)
        for rank, item in enumerate(vector_results):
            doc_id = item['id']
            if doc_id not in fused_scores:
                fused_scores[doc_id] = {"item": item, "score": 0}
            # å…¬å¼ï¼šWeight * (1 / (k + rank))
            fused_scores[doc_id]["score"] += weight_vector * (1 / (k + rank + 1))
            
        # å¤„ç† BM25 ç»“æœ (åŠ æƒ)
        for rank, item in enumerate(bm25_results):
            doc_id = item['id']
            if doc_id not in fused_scores:
                fused_scores[doc_id] = {"item": item, "score": 0}
            # å…¬å¼ï¼šWeight * (1 / (k + rank))
            fused_scores[doc_id]["score"] += weight_bm25 * (1 / (k + rank + 1))
            
        # 4. æ’åºå¹¶å– Top K
        sorted_results = sorted(fused_scores.values(), key=lambda x: x['score'], reverse=True)
        final_output = [res['item'] for res in sorted_results[:top_k]]
        
        return final_output

    def search(self, query, top_k=3):
        """ä¿ç•™åŸæ¥å£ï¼ŒæŒ‡å‘æ··åˆæœç´¢"""
        return self.search_hybrid(query, top_k)

# åˆ›å»ºå…¨å±€å•ä¾‹
vector_db = VectorStore()