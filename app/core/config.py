# æ–‡ä»¶è·¯å¾„: app/core/config.py
"""
åº”ç”¨é…ç½®æ¨¡å—

æ”¯æŒå¤š LLM ä¾›åº”å•†é…ç½®:
- OpenAI (GPT-4, GPT-4o ç­‰)
- DeepSeek (deepseek-chat ç­‰)
- Anthropic (Claude ç³»åˆ—)
- Google Gemini (gemini-1.5-pro ç­‰)
"""
import os
from dotenv import load_dotenv
from typing import Optional

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()


class Settings:
    """åº”ç”¨é…ç½®ç±»"""
    
    # --- LLM ä¾›åº”å•†é€‰æ‹© ---
    # æ”¯æŒ: "openai", "deepseek", "anthropic", "gemini"
    LLM_PROVIDER = os.getenv("LLM_PROVIDER", "deepseek")
    
    # --- API Keys (æ ¹æ®é€‰æ‹©çš„ä¾›åº”å•†é…ç½®å¯¹åº”çš„ Key) ---
    GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
    
    # OpenAI
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")  # å¯é€‰è‡ªå®šä¹‰ç«¯ç‚¹
    
    # DeepSeek
    DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
    DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
    
    # Anthropic (Claude)
    ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
    
    # Google Gemini
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    GEMINI_BASE_URL = os.getenv("GEMINI_BASE_URL")  # å¯é€‰ OpenAI å…¼å®¹ç«¯ç‚¹
    
    # SiliconFlow (Embedding)
    SILICON_API_KEY = os.getenv("SILICON_API_KEY")
    
    # --- æ¨¡å‹é…ç½® ---
    # å¦‚æœä¸æŒ‡å®šï¼Œå°†ä½¿ç”¨å„ä¾›åº”å•†çš„é»˜è®¤æ¨¡å‹
    MODEL_NAME = os.getenv("MODEL_NAME")
    
    # --- æœåŠ¡é…ç½® ---
    HOST = os.getenv("HOST", "127.0.0.1")
    PORT = int(os.getenv("PORT", 8000))
    
    # --- LLM é»˜è®¤å‚æ•° ---
    LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.1"))
    LLM_MAX_TOKENS = int(os.getenv("LLM_MAX_TOKENS", "4096"))
    LLM_TIMEOUT = int(os.getenv("LLM_TIMEOUT", "600"))
    
    @property
    def current_api_key(self) -> Optional[str]:
        """è·å–å½“å‰é€‰æ‹©çš„ä¾›åº”å•†çš„ API Key"""
        key_mapping = {
            "openai": self.OPENAI_API_KEY,
            "deepseek": self.DEEPSEEK_API_KEY,
            "anthropic": self.ANTHROPIC_API_KEY,
            "gemini": self.GEMINI_API_KEY,
        }
        return key_mapping.get(self.LLM_PROVIDER.lower())
    
    @property
    def current_base_url(self) -> Optional[str]:
        """è·å–å½“å‰é€‰æ‹©çš„ä¾›åº”å•†çš„ Base URL"""
        url_mapping = {
            "openai": self.OPENAI_BASE_URL,
            "deepseek": self.DEEPSEEK_BASE_URL,
            "anthropic": None,
            "gemini": self.GEMINI_BASE_URL,
        }
        return url_mapping.get(self.LLM_PROVIDER.lower())
    
    @property
    def default_model_name(self) -> str:
        """è·å–å½“å‰ä¾›åº”å•†çš„é»˜è®¤æ¨¡å‹åç§°"""
        defaults = {
            "openai": "gpt-4o-mini",
            "deepseek": "deepseek-chat",
            "anthropic": "claude-3-5-sonnet-20241022",
            "gemini": "gemini-3-flash-preview",
        }
        return self.MODEL_NAME or defaults.get(self.LLM_PROVIDER.lower(), "default")

    def validate(self):
        """å¯åŠ¨æ—¶æ£€æŸ¥å¿…è¦çš„é…ç½®æ˜¯å¦å­˜åœ¨"""
        provider = self.LLM_PROVIDER.lower()
        print(f"ğŸ”§ LLM Provider: {provider.upper()}")
        
        # 1. æ£€æŸ¥é€‰æ‹©çš„ä¾›åº”å•†çš„ API Key
        if not self.current_api_key:
            key_name = f"{provider.upper()}_API_KEY"
            raise ValueError(
                f"âŒ é”™è¯¯: ç¼ºå°‘ {key_name}ã€‚\n"
                f"   å½“å‰é€‰æ‹©çš„ LLM ä¾›åº”å•†æ˜¯: {provider}\n"
                f"   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® {key_name}ï¼Œæˆ–æ›´æ”¹ LLM_PROVIDER ä¸ºå…¶ä»–ä¾›åº”å•†ã€‚"
            )
        
        # 2. æ£€æŸ¥ SiliconCloud Key (Embedding åŠŸèƒ½)
        if not self.SILICON_API_KEY:
            print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° SILICON_API_KEYï¼Œå‘é‡æ£€ç´¢åŠŸèƒ½å¯èƒ½æ— æ³•å·¥ä½œã€‚")
            
        # 3. æ£€æŸ¥ GitHub Token (å¯é€‰ä½†å»ºè®®)
        if not self.GITHUB_TOKEN:
            print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° GITHUB_TOKENï¼ŒGitHub API è¯·æ±‚å°†å—åˆ°æ¯å°æ—¶ 60 æ¬¡çš„ä¸¥æ ¼é™åˆ¶ã€‚")
        
        print(f"âœ… é…ç½®éªŒè¯é€šè¿‡ (Model: {self.default_model_name})")


settings = Settings()
# ç«‹å³æ‰§è¡ŒéªŒè¯ï¼Œç¡®ä¿å¯åŠ¨æ—¶å°±æš´éœ²é—®é¢˜
settings.validate()